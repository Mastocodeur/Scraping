{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f333bd-2609-4858-b410-1414c00cd3d6",
   "metadata": {},
   "source": [
    "# <center>Atelier Scraping </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e655cd2-053b-47a2-baf0-9eabfc01b7dc",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../images/scrappeur.png\" width=\"600\" height=\"300\">\n",
    "</div>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f4c6a6-7867-4f2f-8653-df8ceea4569c",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeb85f9-b3c0-4541-a7cf-9085482f8cdb",
   "metadata": {},
   "source": [
    "Commençons par mettre en place les bases du scraping. Scraper, c'est savoir lire ce qui se cache derrière un site. Avec un simple clic droit et inspecter l'élément, on arrive assez simplement à accéder au code HTML de la page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a46eec-b1f5-46c9-837f-956dcef224c4",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../images/du site au html.png\" width=\"800\" height=\"400\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408ba027-bc50-4306-ab47-58cd2b1ca486",
   "metadata": {},
   "source": [
    "Voici un petit [Formulaire HTML](formulaire_html.md). Il permet rapidemment d'apprendre ou se remémorer les balises principales permettant de lire du HTML et d'ainsi repérer les différents éléments d'une page web."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c58b036-74aa-43bd-8739-cbde358365a1",
   "metadata": {},
   "source": [
    "Ensuite, il faut choisir un outil de scraping : Selenium ou BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd0c361-3575-4c36-978e-3bddfb9ce167",
   "metadata": {},
   "source": [
    "- Selenium est utile pour les pages web dynamiques où le contenu est généré via JavaScript, nécessitant des interactions utilisateur telles que les clics, le défilement, ou la saisie de texte.\n",
    "\n",
    "- BeautifulSoup est une bibliothèque Python utilisée principalement pour parser (analyser) des documents HTML et XML. Elle est utile pour extraire des données structurées à partir de pages web statiques.\n",
    "\n",
    "De manière générale, on préfèrera utiliser Selenium qui permet plus d'actions, mais beautifulsoup reste une option importante. Dans, cette activité on présente donc les deux modules pour se faire la main."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a673eb-db4d-48ac-a680-2c1a2fc47a80",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b651b072-df16-4586-8b2b-6ea80422c1da",
   "metadata": {},
   "source": [
    "## Activité 1a : Récupérer une énigme du Professeur Layton avec Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe749d-4ac0-44b2-a5f4-a2a1d61f7b69",
   "metadata": {},
   "source": [
    "Nous allons voir comment nous pouvons simplement récupérer les éléments principaux d'une page wiki pour s'en faire une base de données. Pour cela, nous allons nous connecter sur https://professeur-layton.fandom.com/fr/wiki/La_travers%C3%A9e_(1). \n",
    "\n",
    "L'idée dans un premier temps sera de récupérer :\n",
    "- le titre,\n",
    "- le numéro de l'énigme,\n",
    "- l'énoncé,\n",
    "- la solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f454db-be86-4540-b80b-8f78634070c6",
   "metadata": {},
   "source": [
    "###### Import des modules python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1214a01e-fc63-46f2-9da7-d082a90e10cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee0ba2e-8543-4dc9-8b6c-5fb43f87c517",
   "metadata": {},
   "source": [
    "###### Lancer l'ouverture du navigateur et la connexion à l'énigme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e40e8b8a-52fa-458a-8ab5-6ed70c070d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise en place du driver chrome\n",
    "service = Service(executable_path=ChromeDriverManager().install())\n",
    "# Ajouter des options \n",
    "chrome_options = Options()\n",
    "# Désactiver la propriété qui révèle le contrôle par l'automatisation\n",
    "chrome_options.add_argument('--disable-blink-features=AutomationControlled')  \n",
    "# On lance Chrome en fournissant le driver et en renseignant les options\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "# On renseigne l'URL que l'on veut scraper\n",
    "url = \"https://professeur-layton.fandom.com/fr/wiki/La_travers%C3%A9e_(1)\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd46d9c-4ce6-46d5-8a46-c1e06552e73f",
   "metadata": {},
   "source": [
    "###### Récupération astucieuse des éléments Web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ff8bf-f906-477d-aebe-12710764cbc4",
   "metadata": {},
   "source": [
    "C'est ici que l'on introduit les différents sélecteurs d'éléments Web : \n",
    "\n",
    "- ID = \"id\"\n",
    "- NAME = \"name\"\n",
    "- XPATH = \"xpath\"\n",
    "- LINK_TEXT = \"link text\"\n",
    "- PARTIAL_LINK_TEXT = \"partial link text\"\n",
    "- TAG_NAME = \"tag name\"\n",
    "- CLASS_NAME = \"class name\"\n",
    "- CSS_SELECTOR = \"css selector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b89c775-44ab-4254-8400-1a71f7eadd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération du titre :\n",
    "title = driver.find_element(By.XPATH ,'//*[@id=\"firstHeading\"]')\n",
    "\n",
    "# Récupération du numéro de l'énigme :\n",
    "num_enigme = driver.find_element(By.XPATH ,'//*[@id=\"mw-content-text\"]/div/div[1]/div[2]/table/tbody/tr[4]/td')\n",
    "\n",
    "# Récupération de l'énoncé de l'énigme :\n",
    "enonce = driver.find_element(By.XPATH ,'//*[@id=\"Énoncé\"]')\n",
    "enigme_enonce = enonce.find_elements(By.XPATH, '//h2[span[@id=\"Énoncé\"]]/following-sibling::p | //h2[span[@id=\"Énoncé\"]]/following-sibling::ul')\n",
    "\n",
    "# Récupération de la réponse :\n",
    "reponse = driver.find_element(By.XPATH, '//*[@id=\"mw-content-text\"]/div/p[8]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d45a493-7cc7-42f3-8929-83e1b98b4159",
   "metadata": {},
   "source": [
    "###### Lecture des éléments Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43ab2d7f-d104-48c2-9a9b-bab9d8a34ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = title.text\n",
    "num_enigme = num_enigme.text\n",
    "enigme_enonce = [elem.text for elem in enigme_enonce]\n",
    "enigme_enonce = \"\\n\".join(enigme_enonce)\n",
    "reponse = reponse.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d377e730-ebbf-4aae-8c74-ccee3087e128",
   "metadata": {},
   "source": [
    "###### Stockage dans un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "079d8e96-471e-4c4b-8643-6492ec52ee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'La traversée (1)', 'number': '007', 'description': \"Vous devez amener les trois loups et les trois poussins sur l'autre rive. Attention à bien respecter les règles suivantes\\xa0:\\n\\nLe radeau ne peut accueillir plus de deux animaux.\\nVous ne pouvez pas déplacer le radeau s'il est vide.\\nS'il y a plus de loups que de poussins sur une des rives, les loups mangeront les pauvres volatiles sans défense et il vous faudra recommencer depuis le début.\\nVous n'avez pas de limite de déplacement, mais il est possible de résoudre cette énigme en 11 déplacements.\\n\", 'solution': 'Beau travail\\xa0!\\n Cette énigme peut être résolue en 11 déplacements. Combien en avez-vous fait\\xa0?\\n Il existe de nombreuses variations de ce problème. On a retrouvé de telles énigmes dans des écrits vieux de plus de mille ans.\\n'}\n"
     ]
    }
   ],
   "source": [
    "# Initialiser le dictionnaire de listes\n",
    "data = {\n",
    "    'title': title,\n",
    "    'number': num_enigme,\n",
    "    'description': enigme_enonce,\n",
    "    'solution': reponse\n",
    "}\n",
    "# Afficher le dictionnaire\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7387a7-921e-4ba5-b75e-b5d6ce70a10c",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7048a99-f382-4a77-8903-1d0894fa5e58",
   "metadata": {},
   "source": [
    "## Activité 1b : Récupérer une énigme du Professeur Layton avec BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e864852-a2ae-4ade-b39c-5b22ce681b9d",
   "metadata": {},
   "source": [
    "###### Import des modules python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b32e7519-3981-4e11-91a2-d9f313eadeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a05b38-e998-4ee4-90ae-3c148945110f",
   "metadata": {},
   "source": [
    "###### Lancement d'une requête permettant de récupérer tout le code source de l'url à scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb2426fc-21e0-4594-ab51-6b666e2fcd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://professeur-layton.fandom.com/fr/wiki/La_travers%C3%A9e_(1)\"\n",
    "data  = requests.get(url).text\n",
    "soup = BeautifulSoup(data,\"html5lib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c615aae-9c55-4615-99b5-47f661218d68",
   "metadata": {},
   "source": [
    "###### Afficher le code source de la page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50d1fc48-d0ae-4518-91ca-33ce3da52a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead3f57-2b0f-4d39-b084-098eece9aa66",
   "metadata": {},
   "source": [
    "###### Récupération des éléments Web à partir du soup.prettify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c2e4cd9-ba53-4656-91d1-ec0b9ffa62e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La traversée (1)\n",
      "\n",
      "\n",
      "https://professeur-layton.fandom.com/fr/wiki/La_travers%C3%A9e_(1)\n",
      "007\n",
      "\n",
      "\n",
      "Vous devez amener les trois loups et les trois poussins sur l'autre rive. Attention à bien respecter les règles suivantes :\n",
      "\n",
      "Le radeau ne peut accueillir plus de deux animaux.\n",
      "Vous ne pouvez pas déplacer le radeau s'il est vide.\n",
      "S'il y a plus de loups que de poussins sur une des rives, les loups mangeront les pauvres volatiles sans défense et il vous faudra recommencer depuis le début.\n",
      "Vous n'avez pas de limite de déplacement, mais il est possible de résoudre cette énigme en 11 déplacements.\n",
      "\n",
      "Beau travail !\n",
      " Cette énigme peut être résolue en 11 déplacements. Combien en avez-vous fait ?\n",
      " Il existe de nombreuses variations de ce problème. On a retrouvé de telles énigmes dans des écrits vieux de plus de mille ans.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title = soup.find('meta', attrs={'property': \"og:title\"})\n",
    "title = title.get(\"content\")\n",
    "print(title)\n",
    "print(\"\\n\")\n",
    "\n",
    "url_enigme = soup.find('meta', attrs={'property': \"og:url\"})\n",
    "print(url_enigme.get(\"content\"))\n",
    "\n",
    "# Trouver la balise <tr> contenant \"Professeur Layton et l'Étrange Village\"\n",
    "layton_row = soup.find('a', title=\"Professeur Layton et l'Étrange Village\").find_parent('tr')\n",
    "# Trouver la balise <tr> suivante\n",
    "numero_row = layton_row.find_next_sibling('tr')\n",
    "# Extraire le contenu de la balise <td> contenant le numéro\n",
    "numero = numero_row.find('td').text.strip()\n",
    "print(numero)\n",
    "\n",
    "print(\"\\n\")\n",
    "start_element = soup.find('span', id='Énoncé').find_parent('h2')\n",
    "\n",
    "# Initialize an empty list to collect the text\n",
    "text_list = []\n",
    "\n",
    "# Iterate over all next siblings of the start element\n",
    "for sibling in start_element.find_next_siblings():\n",
    "    if sibling.name == 'h2':  # Stop if we reach another h2 element\n",
    "        break\n",
    "    if sibling.name in ['p', 'ul']:  # Collect text from p and ul elements\n",
    "        text_list.append(sibling.get_text())\n",
    "\n",
    "# Join the collected text into a single string\n",
    "enigme_enonce = \"\\n\".join(text_list)\n",
    "\n",
    "# Print the resulting string\n",
    "print(enigme_enonce)\n",
    "\n",
    "##########\n",
    "\n",
    "start_element = soup.find('span', id='Résolution').find_parent('h3')\n",
    "\n",
    "# Initialize an empty list to collect the text\n",
    "text_list = []\n",
    "\n",
    "# Iterate over all next siblings of the start element\n",
    "for sibling in start_element.find_next_siblings():\n",
    "    if sibling.name == 'h3':  # Stop if we reach another h2 element\n",
    "        break\n",
    "    if sibling.name in ['p', 'ul']:  # Collect text from p and ul elements\n",
    "        text_list.append(sibling.get_text())\n",
    "\n",
    "# Join the collected text into a single string\n",
    "reponse = \" \".join(text_list)\n",
    "print(reponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e23c021-0b03-457e-9216-634fb285b55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'La traversée (1)', 'number': '007', 'description': \"Vous devez amener les trois loups et les trois poussins sur l'autre rive. Attention à bien respecter les règles suivantes\\xa0:\\n\\nLe radeau ne peut accueillir plus de deux animaux.\\nVous ne pouvez pas déplacer le radeau s'il est vide.\\nS'il y a plus de loups que de poussins sur une des rives, les loups mangeront les pauvres volatiles sans défense et il vous faudra recommencer depuis le début.\\nVous n'avez pas de limite de déplacement, mais il est possible de résoudre cette énigme en 11 déplacements.\\n\", 'solution': 'Beau travail\\xa0!\\n Cette énigme peut être résolue en 11 déplacements. Combien en avez-vous fait\\xa0?\\n Il existe de nombreuses variations de ce problème. On a retrouvé de telles énigmes dans des écrits vieux de plus de mille ans.\\n'}\n"
     ]
    }
   ],
   "source": [
    "# Initialiser le dictionnaire de listes\n",
    "data = {\n",
    "    'title': title,\n",
    "    'number': numero,\n",
    "    'description': enigme_enonce,\n",
    "    'solution': reponse\n",
    "}\n",
    "# Afficher le dictionnaire\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4dd990-fa58-4cf6-9872-dff74dee60f9",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92163375-fd98-47d7-9f1f-02ef3ce61d00",
   "metadata": {},
   "source": [
    "## Activité 2 : Généralisation à plusieurs énigmes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3a73f1-7f1d-4772-8bb0-a77624b5b1e6",
   "metadata": {},
   "source": [
    "###### Lancement d'une requête permettant de récupérer tout le code source de l'url à scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6b107ff9-1051-4bff-bfd9-af8824328b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://professeur-layton.fandom.com/fr/wiki/Cat%C3%A9gorie:%C3%89nigmes\"\n",
    "data  = requests.get(url).text\n",
    "soup = BeautifulSoup(data,\"html5lib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ecca56-e498-4c9b-8749-eb9f39025349",
   "metadata": {},
   "source": [
    "###### Afficher le code source de la page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b45dc254-8e02-4e3b-aa78-297b2c1a621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1ea655-d96a-4e0d-882a-7d789e1d39ec",
   "metadata": {},
   "source": [
    "###### Récuperer tous les liens des énigmes et n'en prendre que 5 aléatoirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b0c547ee-5a10-4401-b070-b8d08e66f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver tous les éléments <a> avec la classe \"category-page__member-link\"\n",
    "links = soup.find_all('a', class_='category-page__member-link')\n",
    "\n",
    "# Extraire les attributs href\n",
    "hrefs = [link.get('href') for link in links]\n",
    "\n",
    "# Afficher les hrefs\n",
    "#print(hrefs)\n",
    "#print(len(hrefs))\n",
    "\n",
    "# Sélectionner aléatoirement 5 hrefs\n",
    "hrefs = random.sample(hrefs, 5)\n",
    "\n",
    "# Afficher les hrefs sélectionnés aléatoirement\n",
    "#print(random_hrefs)\n",
    "#print(len(random_hrefs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64fd639-3e47-48a7-895c-8c4357dd072d",
   "metadata": {},
   "source": [
    "###### Créons une fonction permettant de répéter les étapes d'extraction de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df501c30-439c-4881-86b0-4d2be844c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collecte_enigme(racine, href):\n",
    "    url = racine+href\n",
    "    data  = requests.get(url).text\n",
    "    soup = BeautifulSoup(data,\"html.parser\")\n",
    "  \n",
    "    # Récupération du titre\n",
    "    title = soup.find('meta', attrs={'property': \"og:title\"})\n",
    "    title = title.get(\"content\")\n",
    "\n",
    "    # Récupération url\n",
    "    url_enigme = soup.find('meta', attrs={'property': \"og:url\"})\n",
    "    url_enigme = url_enigme.get(\"content\")\n",
    "\n",
    "    # Récupération de l'image\n",
    "    src_tags = soup.find_all(src=True)\n",
    "    # Extraire les valeurs de src\n",
    "    src_urls = [tag['src'] for tag in src_tags]\n",
    "    longest_src = max(src_urls, key=len) if src_urls else None\n",
    "    image = longest_src\n",
    "\n",
    "    # Récupération de l'énigme\n",
    "    try:\n",
    "        enigme_title = soup.find('span', {'class': 'mw-headline', 'id': 'Énoncé'})\n",
    "        # Trouver le paragraphe suivant le titre de la section \"Énoncé\"\n",
    "        enigme_paragraph = enigme_title.find_next('p')\n",
    "        # Extraire le texte du paragraphe\n",
    "        enigme = enigme_paragraph.get_text(strip=True)\n",
    "        \n",
    "    except :\n",
    "        enigme = image\n",
    "        \n",
    "    # Récupération de la réponse\n",
    "    try :\n",
    "        \n",
    "        reponse_title = soup.find('span', {'class': 'mw-headline', 'id': 'Solution'})\n",
    "        reponse_paragraph = reponse_title.find_next('p')\n",
    "        reponse = reponse_paragraph.get_text(strip=True)\n",
    "    except :\n",
    "        a_tag = soup.find('a', class_='image')\n",
    "        if a_tag:\n",
    "            reponse = a_tag.get('href')\n",
    "        else:\n",
    "            reponse =\"La réponse n'a pas été loadé correctement\"\n",
    "\n",
    "    # Récupération des indices\n",
    "    tabs = soup.select('ul.wds-tabs li.wds-tabs__tab a')\n",
    "    contents = soup.select('div.wds-tab__content')\n",
    "    # Extract each index content into a list\n",
    "    indices = []\n",
    "    for i, tab in enumerate(tabs):\n",
    "        if i < len(contents):\n",
    "            content_divs = contents[i].select('div[style*=\"overflow-y:auto\"]')\n",
    "            if content_divs:\n",
    "                content = content_divs[0].get_text(strip=True)\n",
    "                indices.append(content)\n",
    "        \n",
    "    # Append the collected data as a dictionary\n",
    "    data = []\n",
    "    data.append({'title': title, 'url': url_enigme, 'image': image, 'enigme': enigme, 'indices': indices,'solution': reponse})\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2a839e-1db8-4d74-9a8b-802bf0892707",
   "metadata": {},
   "source": [
    "###### Utilisation de la fonction et stockage dans un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57b83f25-c3b8-49c1-bb69-e5d43993dc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "racine = \"https://professeur-layton.fandom.com\"\n",
    "df_final = pd.DataFrame()\n",
    "for href in hrefs:\n",
    "    #print(href)\n",
    "    df_final = pd.concat([df_final, collecte_enigme(racine,href)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145124c0-949a-435a-b620-98c23523a31a",
   "metadata": {},
   "source": [
    "###### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "059c5314-9042-4de1-8e89-0396335db08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>url</th>\n",
       "      <th>Image</th>\n",
       "      <th>Enigme</th>\n",
       "      <th>Indices</th>\n",
       "      <th>Solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Photo choc</td>\n",
       "      <td>https://professeur-layton.fandom.com/fr/wiki/P...</td>\n",
       "      <td>https://static.wikia.nocookie.net/layton/image...</td>\n",
       "      <td>Quelques amis ont eu l'idée folle d'aller fair...</td>\n",
       "      <td>[Il y a en tout six karts blancs.Les amis de l...</td>\n",
       "      <td>Il suffit d'entourer le kart blanc du milieu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Histoire de gélules</td>\n",
       "      <td>https://professeur-layton.fandom.com/fr/wiki/H...</td>\n",
       "      <td>https://static.wikia.nocookie.net/layton/image...</td>\n",
       "      <td>Cet homme s'est fait prescrire dix gélules. À ...</td>\n",
       "      <td>[S'il veut indiquer l'ordre dans lequel il doi...</td>\n",
       "      <td>La réponse est 8.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Les trois parapluies</td>\n",
       "      <td>https://professeur-layton.fandom.com/fr/wiki/L...</td>\n",
       "      <td>https://static.wikia.nocookie.net/layton/image...</td>\n",
       "      <td>Ces trois jeunes filles ont déposé leur parapl...</td>\n",
       "      <td>[Ne perdez pas de vue ce que l'on vous demande...</td>\n",
       "      <td>La réponse est 0.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chat balance...</td>\n",
       "      <td>https://professeur-layton.fandom.com/fr/wiki/C...</td>\n",
       "      <td>https://static.wikia.nocookie.net/layton/image...</td>\n",
       "      <td>Des chats en peluche de différentes couleurs s...</td>\n",
       "      <td>[Utilisez les exemples 1 et 2 pour simplifier ...</td>\n",
       "      <td>La balance penche vers A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trop d'anneaux</td>\n",
       "      <td>https://professeur-layton.fandom.com/fr/wiki/T...</td>\n",
       "      <td>https://static.wikia.nocookie.net/layton/image...</td>\n",
       "      <td>Ci-dessous se trouvent six anneaux.</td>\n",
       "      <td>[Essayez de visualiser à quoi ressemble une ch...</td>\n",
       "      <td>La réponse est le maillon D.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Title                                                url  \\\n",
       "0            Photo choc  https://professeur-layton.fandom.com/fr/wiki/P...   \n",
       "1   Histoire de gélules  https://professeur-layton.fandom.com/fr/wiki/H...   \n",
       "2  Les trois parapluies  https://professeur-layton.fandom.com/fr/wiki/L...   \n",
       "3       Chat balance...  https://professeur-layton.fandom.com/fr/wiki/C...   \n",
       "4        Trop d'anneaux  https://professeur-layton.fandom.com/fr/wiki/T...   \n",
       "\n",
       "                                               Image  \\\n",
       "0  https://static.wikia.nocookie.net/layton/image...   \n",
       "1  https://static.wikia.nocookie.net/layton/image...   \n",
       "2  https://static.wikia.nocookie.net/layton/image...   \n",
       "3  https://static.wikia.nocookie.net/layton/image...   \n",
       "4  https://static.wikia.nocookie.net/layton/image...   \n",
       "\n",
       "                                              Enigme  \\\n",
       "0  Quelques amis ont eu l'idée folle d'aller fair...   \n",
       "1  Cet homme s'est fait prescrire dix gélules. À ...   \n",
       "2  Ces trois jeunes filles ont déposé leur parapl...   \n",
       "3  Des chats en peluche de différentes couleurs s...   \n",
       "4                Ci-dessous se trouvent six anneaux.   \n",
       "\n",
       "                                             Indices  \\\n",
       "0  [Il y a en tout six karts blancs.Les amis de l...   \n",
       "1  [S'il veut indiquer l'ordre dans lequel il doi...   \n",
       "2  [Ne perdez pas de vue ce que l'on vous demande...   \n",
       "3  [Utilisez les exemples 1 et 2 pour simplifier ...   \n",
       "4  [Essayez de visualiser à quoi ressemble une ch...   \n",
       "\n",
       "                                        Solution  \n",
       "0  Il suffit d'entourer le kart blanc du milieu.  \n",
       "1                              La réponse est 8.  \n",
       "2                              La réponse est 0.  \n",
       "3                      La balance penche vers A.  \n",
       "4                   La réponse est le maillon D.  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_row', 7)\n",
    "pd.set_option('display.max_column', 6)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e582c-54d1-4617-82ae-d05b7ec943bf",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137e12c8-22b2-407b-94df-ae5e7601e28d",
   "metadata": {},
   "source": [
    "Nous avons finalement réussi à se constituer un DataFrame à partir d'un site web ! \n",
    "Ce qu'il faut retenir, c'est que BeautifulSoup est très utile pour les sites dit \"ouverts\" et pour de la répetition massive de collecte d'infos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
