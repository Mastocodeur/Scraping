<div align="center" markdown>
# [Atelier Scraping](https://github.com/Mastocodeur/Tutorial_Scraping/)

Atelier pour d√©couvrir deux modules python de scraping : Selenium et BeautifulSoup.

[![PyPI - Version](https://img.shields.io/pypi/v/mmg?color)](https://pypi.org/project/mmg/)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/mmg)
![GitHub code size in bytes](https://img.shields.io/github/languages/code-size/ryul1206/multilingual-markdown)
[![PyPI - License](https://img.shields.io/pypi/l/mmg)](https://github.com/ryul1206/multilingual-markdown/blob/main/LICENSE)

üåè
[**English**](https://github.com/ryul1206/multilingual-markdown/blob/main/README.md) |
Fran√ßais |



</div>





## Table des Mati√®res

1. [Qu'est-ce que le scraping ?](#qu-est-ce-que-le-scraping)
2. [Introduction au HTML](#introduction-au-html)
3. [L√©gislation autour du scraping](#l√©gislation-autour-du-scraping)
4. [Selenium vs BeautifulSoup](#selenium-vs-beautifulsoup)
5. [Les diff√©rentes fa√ßons de localiser des √©l√©ments Web](#les-diff√©rentes-fa√ßons-de-localiser-des-√©l√©ments-web)
6. [Avenir du scraping : LaVague](#avenir-du-scraping-lavague)
7. [Bonus: robots.txt](#bonus-robots.txt)
8. [Sources et documentation](#sources-et-documentation)


## Le scraping, qu'est-ce que c'est ?

Le scraping, ou "web scraping", est une technique utilis√©e pour extraire automatiquement des donn√©es √† partir de sites web. Cette m√©thode permet de r√©cup√©rer des informations structur√©es ou semi-structur√©es disponibles sur des pages web, que l'on peut ensuite analyser, traiter ou stocker pour divers usages. Mais il permet √©galement d'automatiser des t√¢ches sur un site. Il existe plusieurs module python permettant de faire du scraping : BeautifulSoup, Selenium, Scrapy, Requests, Octoparse.

Nous utiliserons BeautifulSoup et Selenium dans ces diff√©rents ateliers.

## Introduction au HTML
Scraper n√©cessite de savoir interpr√©ter les codes sources des pages web, et donc comprendre le HTML.

Voici un petit [Formulaire HTML](formulaire_html.md). Il permet rapidemment d'apprendre ou se rem√©morer les balises principales permettant de lire du HTML et d'ainsi rep√©rer les diff√©rents √©l√©ments d'une page web.

## L√©gislation autour du scraping

Le scraping web est g√©n√©ralement autoris√© dans les cas suivants :</p>
- Les donn√©es extraites sont des donn√©es accessibles au public.</li>
- Les informations recueillies ne sont pas prot√©g√©es par un login.</li>

De mani√®re g√©n√©rale, il faut souvent √™tre prudent lors du scraping, notamment vis-√†-vis des Termes de service, des donn√©es prot√©g√©es par le droit d'auteur et des donn√©es personnelles (car les donn√©es personnelles sont g√©n√©ralement prot√©g√©es par les lois sur la propri√©t√© intellectuelle).

En droit de la concurrence, le web scraping peut √™tre qualifi√© d'un acte de concurrence d√©loyale. 

La CNIL a par exemple condamn√© la soci√©t√© Nestor √† une amende de 20000 euros car elle avait construit sa base de prospects en ayant recours √† la pratique de web scraping √† partir de donn√©es accessibles sur le r√©seau social professionnel Linkedin (Pour plus d'infos voir les articles mentionn√©s).

## Selenium vs BeautifulSoup

Selenium est utile pour les pages web dynamiques o√π le contenu est g√©n√©r√© via JavaScript, n√©cessitant des interactions utilisateur telles que les clics, le d√©filement, ou la saisie de texte.

BeautifulSoup est une biblioth√®que Python utilis√©e principalement pour parser (analyser) des documents HTML et XML. Elle est utile pour extraire des donn√©es structur√©es √† partir de pages web statiques.

## Les diff√©rentes fa√ßon de localiser des √©l√©ments Web 

- ID = "id"
- NAME = "name"
- XPATH = "xpath"
- LINK_TEXT = "link text"
- PARTIAL_LINK_TEXT = "partial link text"
- TAG_NAME = "tag name"
- CLASS_NAME = "class name"
- CSS_SELECTOR = "css selector"


## Avenir du scraping : LaVague

[lavague.ai](https://github.com/lavague-ai)


## Bonus: robots.txt

Pour acc√©der √† ce fichier, il s'agit de taper : url_racine/robots.txt

Ce fichier permet de cadrer le trafic des robots d'exploration. On peut gr√¢ce √† ce fichier connaitre les limitations impos√©es aux robots d'exploration.


## Sources et documentation

- [Tout sur le web scraping](https://kinsta.com/fr/base-de-connaissances/web-scraping/)

- [Web scraping : est-ce l√©gal](https://www.captaincontrat.com/protection-des-creations/cgv-cgu-cga/web-scraping-est-ce-legal-me-marcotte)

- [Le web scraping est-il l√©gal ?](https://www.iubenda.com/fr/help/111962-le-web-scraping-est-il-legal-ce-que-vous-devez-savoir#:~:text=La%20l%C3%A9galit%C3%A9%20du%20web%20scraping&text=Ne%20soyez%20pas%20trop%20enthousiaste,pas%20prot%C3%A9g%C3%A9es%20par%20un%20login)


- [Le cas Nestor (1)](https://www.alerionavocats.com/condamnation-societe-nestor-prospection-commerciale-fondee-interet-legitime-responsable-traitement-enseignements-tirer/)

- [Le cas Nestor (2)](https://www.plravocats.fr/blog/data-protection-rgpd/la-societe-nestor-sanctionee-par-la-cnil)

- [Pr√©sentation du fichier robots.txt](https://developers.google.com/search/docs/crawling-indexing/robots/intro?hl=fr)

- [Documentation Selenium](https://selenium-python.readthedocs.io/)

- [Documentation BeautifulSoup](https://beautiful-soup-4.readthedocs.io/en/latest/)